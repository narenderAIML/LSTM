{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5DB8WFiVfai"
      },
      "source": [
        "# Step 1 - Import the necessary libraries\n",
        "import numpy\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "from keras.layers import Dropout \n",
        "from keras.layers import LSTM \n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.utils import np_utils "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq1mTjHGVkrC",
        "outputId": "24aaee65-f023-4f0b-f21a-99796f09be16"
      },
      "source": [
        "# Step 2 - load the sample data\n",
        "Sample_data = \"/content/NLP.txt\"\n",
        "wonderland_text = open(Sample_data, 'r', encoding='utf-8').read()\n",
        "wonderland_text = wonderland_text.lower()\n",
        "print(wonderland_text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alice was beginning to get very tired of sitting by her sister\n",
            "on the bank, and of having nothing to do:  once or twice she had\n",
            "peeped into the book her sister was reading, but it had no\n",
            "pictures or conversations in it, `and what is the use of a book,'\n",
            "thought alice `without pictures or conversation?'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxz0a2EK1a2p",
        "outputId": "05e2abb0-5b69-4032-c6bd-d44580a6e672"
      },
      "source": [
        "# Step 3 - Create mapping of unique characters and integers\n",
        "My_characters = sorted(list(set(wonderland_text)))\n",
        "character_to_integer = dict((c, i) for i, c in enumerate(My_characters))\n",
        "character_to_integer"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " \"'\": 2,\n",
              " ',': 3,\n",
              " ':': 4,\n",
              " '?': 5,\n",
              " '`': 6,\n",
              " 'a': 7,\n",
              " 'b': 8,\n",
              " 'c': 9,\n",
              " 'd': 10,\n",
              " 'e': 11,\n",
              " 'f': 12,\n",
              " 'g': 13,\n",
              " 'h': 14,\n",
              " 'i': 15,\n",
              " 'k': 16,\n",
              " 'l': 17,\n",
              " 'n': 18,\n",
              " 'o': 19,\n",
              " 'p': 20,\n",
              " 'r': 21,\n",
              " 's': 22,\n",
              " 't': 23,\n",
              " 'u': 24,\n",
              " 'v': 25,\n",
              " 'w': 26,\n",
              " 'y': 27}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fss9Gg1e2tsJ",
        "outputId": "28ecfb2f-519d-4bcf-c3ea-c9eff25195d7"
      },
      "source": [
        "# Step 4 - Summarize the data\n",
        "wonder_chars = len(wonderland_text)\n",
        "wonder_vocab = len(My_characters)\n",
        "print(\"Total Characters Present in the Sample data: \", wonder_chars)\n",
        "print(\"Total Vocab in the data: \", wonder_vocab)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters Present in the Sample data:  303\n",
            "Total Vocab in the data:  28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47fIRg5U3DUO",
        "outputId": "fb01d41c-939e-4725-a29f-7d69ada213f5"
      },
      "source": [
        "# Step 5 - Prepare the dataset\n",
        "sequence_length = 100\n",
        "x_data = []\n",
        "y_data = []\n",
        "for i in range(0, wonder_chars - sequence_length, 1):\n",
        "  sequence_in = wonderland_text[i:i + sequence_length]\n",
        "  sequence_out = wonderland_text[i + sequence_length]\n",
        "  x_data.append([character_to_integer[char] for char in sequence_in])\n",
        "  y_data.append(character_to_integer[sequence_out])\n",
        "pattern_nn = len(x_data)\n",
        "print(\"Result of total patterns:\", pattern_nn)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result of total patterns: 203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_02gl8U3Lra"
      },
      "source": [
        "# Step 6 - Reshaping the data\n",
        "X = numpy.reshape(x_data, (pattern_nn, sequence_length, 1))\n",
        "X = X / float(wonder_vocab)\n",
        "y = np_utils.to_categorical(y_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foii_Mmo3TDu"
      },
      "source": [
        "#Step 7 - Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_w3ttxG4WGC"
      },
      "source": [
        "# Step 8 - Define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klJTwuRs4jzN",
        "outputId": "ec24d508-dacc-4fb3-8864-434973640448"
      },
      "source": [
        "# Step 9 - Fit the model\n",
        "model.fit(X, y, epochs=1, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 20s 510ms/step - loss: 3.3034\n",
            "\n",
            "Epoch 00001: loss improved from inf to 3.30116, saving model to weights-improvement-01-3.3012.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76da42a190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}